{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from pycocotools.coco import COCO\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from transformers import TFViTForImageClassification, ViTImageProcessor\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Paths remain the same as in original code\n",
    "TRAIN_PATH = 'D:/Download/JDownloader/MSCOCO/images/train2017'\n",
    "VAL_PATH = 'D:/Download/JDownloader/MSCOCO/images/val2017'\n",
    "ANNOTATIONS_PATH = 'D:/Download/JDownloader/MSCOCO/annotations'\n",
    "WORKING_DIR = 'D:/Projetos/Mestrado/2024_Topicos_Esp_Sist_Informacao/ARTIGO_FINAL/object_detection_model_compare/working'\n",
    "FILTERED_CATEGORIES = ['person', 'cat', 'dog']\n",
    "\n",
    "\n",
    "# Load and prepare the dataset\n",
    "filtered_csv_path = os.path.join(WORKING_DIR, 'filtered_coco.csv')\n",
    "\n",
    "# Load COCO annotations\n",
    "annotations_file = os.path.join(ANNOTATIONS_PATH, 'instances_train2017.json')\n",
    "coco = COCO(annotations_file)\n",
    "\n",
    "# Get category IDs for the selected categories\n",
    "category_ids = coco.getCatIds(catNms=FILTERED_CATEGORIES)\n",
    "\n",
    "# Generate filtered dataset\n",
    "filtered_data = []\n",
    "for category_id in category_ids:\n",
    "    ann_ids = coco.getAnnIds(catIds=[category_id])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    selected_anns = random.sample(anns, min(1000, len(anns)))\n",
    "    for ann in selected_anns:\n",
    "        image_info = coco.loadImgs(ann['image_id'])[0]\n",
    "        filtered_data.append({\n",
    "            \"image_id\": ann['image_id'],\n",
    "            \"image\": image_info['file_name'],\n",
    "            \"category_id\": ann['category_id']\n",
    "        })\n",
    "\n",
    "# Create and save filtered dataset\n",
    "filtered_df = pd.DataFrame(filtered_data)\n",
    "filtered_df.to_csv(filtered_csv_path, index=False)\n",
    "\n",
    "# Split the dataset\n",
    "data = pd.read_csv(filtered_csv_path)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Load and preprocess functions\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    \"\"\"Load and preprocess an image for ViT.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_data(data, path_prefix):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in data.iterrows():\n",
    "        image_path = os.path.join(path_prefix, row['image'])\n",
    "        images.append(preprocess_image(image_path))\n",
    "        labels.append(row['category_id'])\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Build the model using ViT\n",
    "def build_vit_model(num_classes):\n",
    "    # Create input layer with correct shape (batch, height, width, channels)\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    # Initialize the ViT model\n",
    "    vit = TFViTForImageClassification.from_pretrained(\n",
    "        'google/vit-base-patch32-224-in21k',\n",
    "        num_labels=num_classes\n",
    "    )\n",
    "    \n",
    "    # Create the model\n",
    "    model = tf.keras.Model(\n",
    "        inputs=inputs,\n",
    "        outputs=vit(inputs, training=True).logits\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Main execution code\n",
    "if __name__ == \"__main__\":\n",
    "    # Dataset preparation code remains the same until loading data\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X_train, y_train = load_data(train_data, TRAIN_PATH)\n",
    "    X_test, y_test = load_data(test_data, TRAIN_PATH)\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = to_categorical(label_encoder.fit_transform(y_train))\n",
    "    y_test_encoded = to_categorical(label_encoder.transform(y_test))\n",
    "    \n",
    "    # Build and compile model\n",
    "    model = build_vit_model(len(FILTERED_CATEGORIES))\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train_encoded,\n",
    "    validation_data=(X_test, y_test_encoded),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model_path = os.path.join(WORKING_DIR, 'vit_coco.keras')\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"Trained model saved at {model_path}\")\n",
    "\n",
    "# Plot training accuracy and loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 857191,
     "sourceId": 1462296,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6332084,
     "sourceId": 10239510,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
