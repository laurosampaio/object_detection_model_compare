{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=7.93s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.36s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms import functional as F\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "TRAIN_PATH = 'D:/Download/JDownloader/MSCOCO/images/train2017'\n",
    "VAL_PATH = 'D:/Download/JDownloader/MSCOCO/images/val2017'\n",
    "ANNOTATIONS_PATH = 'D:/Download/JDownloader/MSCOCO/annotations'\n",
    "WORKING_DIR = 'D:/Projetos/Mestrado/2024_Topicos_Esp_Sist_Informacao/ARTIGO_FINAL/object_detection_model_compare/working'\n",
    "\n",
    "# Define constants\n",
    "CATEGORIES = ['person', 'cat', 'dog']\n",
    "NUM_IMAGES_PER_CLASS = 1000\n",
    "NUM_CLASSES = len(CATEGORIES) + 1  # +1 for background\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.005\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0005\n",
    "STEP_SIZE = 3\n",
    "GAMMA = 0.1\n",
    "\n",
    "# Data Preprocessing\n",
    "class CocoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annotation, categories, transforms=None):\n",
    "        self.root = root\n",
    "        self.coco = COCO(annotation)\n",
    "        self.transforms = transforms\n",
    "        self.cat_ids = self.coco.getCatIds(catNms=categories)\n",
    "        self.img_ids = []\n",
    "        for cat_id in self.cat_ids:\n",
    "            self.img_ids.extend(self.coco.getImgIds(catIds=cat_id))\n",
    "        self.img_ids = list(set(self.img_ids))[:NUM_IMAGES_PER_CLASS * len(categories)]\n",
    "        self.img_ids = sorted(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        path = os.path.join(self.root, img_info['file_name'])\n",
    "        image = F.to_tensor(F.pil_to_tensor(F.pil_image_loader(path)))\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id, catIds=self.cat_ids, iscrowd=None)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in anns:\n",
    "            xmin, ymin, width, height = ann['bbox']\n",
    "            boxes.append([xmin, ymin, xmin + width, ymin + height])\n",
    "            labels.append(self.cat_ids.index(ann['category_id']) + 1)\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target = {'boxes': boxes, 'labels': labels}\n",
    "        if self.transforms:\n",
    "            image, target = self.transforms(image, target)\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = CocoDataset(TRAIN_PATH, os.path.join(ANNOTATIONS_PATH, 'instances_train2017.json'), CATEGORIES)\n",
    "val_dataset = CocoDataset(VAL_PATH, os.path.join(ANNOTATIONS_PATH, 'instances_val2017.json'), CATEGORIES)\n",
    "\n",
    "# Split datasets\n",
    "train_indices, val_indices = train_test_split(list(range(len(train_dataset))), test_size=0.2, random_state=42)\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "val_subset = Subset(val_dataset, val_indices)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# Model Setup\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and learning rate scheduler\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "# Training function\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        train_loss += losses.item()\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss / len(data_loader)\n",
    "\n",
    "# Validation function\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            val_loss += losses.item()\n",
    "    return val_loss / len(data_loader)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
    "    val_loss = evaluate(model, val_loader, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    lr_scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), os.path.join(WORKING_DIR, 'fasterrcnn_model.pth'))\n",
    "\n",
    "# Plotting functions\n",
    "def plot_losses(train_losses, val_losses, save_path):\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# Generate and save plots\n",
    "plot_losses(train_losses, val_losses, os.path.join(WORKING_DIR, 'loss_plot.png'))\n",
    "\n",
    "# Note: For ROC curve and mAP, additional code is required to calculate these metrics.\n",
    "# This script focuses on training and saving the model and loss plots."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 857191,
     "sourceId": 1462296,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6332084,
     "sourceId": 10239510,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
