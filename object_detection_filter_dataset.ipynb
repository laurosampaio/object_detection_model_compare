{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from pycocotools.coco import COCO\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for the dataset, anotations, working directory and images\n",
    "TRAIN_PATH = 'D:/Download/JDownloader/MSCOCO/images/train2017'\n",
    "VAL_PATH = 'D:/Download/JDownloader/MSCOCO/images/val2017'\n",
    "ANNOTATIONS_PATH = 'D:/Download/JDownloader/MSCOCO/annotations'\n",
    "WORKING_DIR = 'D:/Projetos/Mestrado/2024_Topicos_Esp_Sist_Informacao/ARTIGO_FINAL/object_detection_model_compare/working'\n",
    "VAL_MODEL_IMG = 'D:/Projetos/Mestrado/2024_Topicos_Esp_Sist_Informacao/ARTIGO_FINAL/object_detection_model_compare/val_model_img'\n",
    "FILTERED_CATEGORIES = ['person', 'cat', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=8.89s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 17, 18]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load COCO annotations\n",
    "annotations_file = os.path.join(ANNOTATIONS_PATH, 'instances_train2017.json')\n",
    "coco = COCO(annotations_file)\n",
    "\n",
    "# Get category IDs for the selected categories\n",
    "category_ids = coco.getCatIds(catNms=FILTERED_CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image count per category:\n",
      "person: 64115\n",
      "cat: 4114\n",
      "dog: 4385\n"
     ]
    }
   ],
   "source": [
    "# Get total image count per category\n",
    "category_image_counts = {}\n",
    "\n",
    "for category_name, category_id in zip(FILTERED_CATEGORIES, category_ids):\n",
    "    # Get all annotation IDs for the category\n",
    "    ann_ids = coco.getAnnIds(catIds=[category_id])\n",
    "    \n",
    "    # Load annotations and extract unique image IDs\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    image_ids = {ann['image_id'] for ann in anns}  # Use a set to ensure uniqueness\n",
    "    \n",
    "    # Count unique images\n",
    "    category_image_counts[category_name] = len(image_ids)\n",
    "\n",
    "# Print results\n",
    "print(\"Total image count per category:\")\n",
    "for category, count in category_image_counts.items():\n",
    "    print(f\"{category}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved to D:\\Projetos\\Mestrado\\2024_Topicos_Esp_Sist_Informacao\\ARTIGO_FINAL\\object_detection_model_compare\\working\\filtered_coco.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate filtered dataset to train the model\n",
    "\n",
    "# Map category IDs to category names\n",
    "categories = coco.loadCats(category_ids)\n",
    "category_id_to_name = {category['id']: category['name'] for category in categories}\n",
    "\n",
    "# Collect up to 1000 annotations per category\n",
    "filtered_data = []\n",
    "for category_id in category_ids:\n",
    "    ann_ids = coco.getAnnIds(catIds=[category_id])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    selected_anns = random.sample(anns, min(1000, len(anns)))\n",
    "    for ann in selected_anns:\n",
    "        image_info = coco.loadImgs(ann['image_id'])[0]\n",
    "        filtered_data.append({\n",
    "            \"image_id\": ann['image_id'],\n",
    "            \"image\": image_info['file_name'],\n",
    "            \"category_id\": ann['category_id'],\n",
    "            \"bbox\": ann['bbox'],\n",
    "            \"label\": category_id_to_name[ann['category_id']],\n",
    "        })\n",
    "\n",
    "# Save filtered data to CSV\n",
    "filtered_csv_path = os.path.join(WORKING_DIR, 'filtered_coco.csv')\n",
    "filtered_df = pd.DataFrame(filtered_data)\n",
    "filtered_df.to_csv(filtered_csv_path, index=False)\n",
    "\n",
    "print(f\"Filtered dataset saved to {os.path.abspath(filtered_csv_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record count per category_id:\n",
      "category_id\n",
      "1     1000\n",
      "17    1000\n",
      "18    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train - Record count per category_id:\n",
      "category_id\n",
      "18    814\n",
      "17    803\n",
      "1     783\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test - Record count per category_id:\n",
      "category_id\n",
      "1     217\n",
      "17    197\n",
      "18    186\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the filtered dataset\n",
    "# Load the filtered CSV\n",
    "data = pd.read_csv(filtered_csv_path)\n",
    "\n",
    "# Display record count per category_id\n",
    "category_counts = data['category_id'].value_counts()\n",
    "print(\"Record count per category_id:\")\n",
    "print(category_counts)\n",
    "print(\"\")\n",
    "\n",
    "# Split into training and testing datasets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display record count per category_id train and test\n",
    "category_train_counts = train_data['category_id'].value_counts()\n",
    "print(\"Train - Record count per category_id:\")\n",
    "print(category_train_counts)\n",
    "print(\"\")\n",
    "\n",
    "category_test_counts = test_data['category_id'].value_counts()\n",
    "print(\"Test - Record count per category_id:\")\n",
    "print(category_test_counts)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset saved to D:\\Projetos\\Mestrado\\2024_Topicos_Esp_Sist_Informacao\\ARTIGO_FINAL\\object_detection_model_compare\\working\\train_data.csv\n",
      "Testing dataset saved to D:\\Projetos\\Mestrado\\2024_Topicos_Esp_Sist_Informacao\\ARTIGO_FINAL\\object_detection_model_compare\\working\\test_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the split datasets\n",
    "train_csv_path = os.path.join(WORKING_DIR, 'train_data.csv')\n",
    "test_csv_path = os.path.join(WORKING_DIR, 'test_data.csv')\n",
    "\n",
    "train_data.to_csv(train_csv_path, index=False)\n",
    "test_data.to_csv(test_csv_path, index=False)\n",
    "\n",
    "print(f\"Training dataset saved to {os.path.abspath(train_csv_path)}\")\n",
    "print(f\"Testing dataset saved to {os.path.abspath(test_csv_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load split datasets\n",
    "train_csv_path = os.path.join(WORKING_DIR, 'train_data.csv')\n",
    "test_csv_path = os.path.join(WORKING_DIR, 'test_data.csv')\n",
    "\n",
    "train_data = pd.read_csv(train_csv_path)\n",
    "test_data = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Validation Filtered dataset saved to D:\\Projetos\\Mestrado\\2024_Topicos_Esp_Sist_Informacao\\ARTIGO_FINAL\\object_detection_model_compare\\working\\val_filtered_coco.csv\n",
      "Record count per category_id:\n",
      "category_id\n",
      "1     200\n",
      "17    200\n",
      "18    200\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate the validation dataset\n",
    "\n",
    "# Load COCO annotations from validation set\n",
    "val_annotations_file = os.path.join(ANNOTATIONS_PATH, 'instances_val2017.json')\n",
    "coco_val = COCO(val_annotations_file)\n",
    "\n",
    "# Collect up to 200 annotations per category\n",
    "val_filtered_data = []\n",
    "for category_id in category_ids:\n",
    "    ann_ids = coco_val.getAnnIds(catIds=[category_id])\n",
    "    anns = coco_val.loadAnns(ann_ids)\n",
    "    selected_anns = random.sample(anns, min(200, len(anns)))\n",
    "    for ann in selected_anns:\n",
    "        image_info = coco_val.loadImgs(ann['image_id'])[0]\n",
    "        val_filtered_data.append({\n",
    "            \"image_id\": ann['image_id'],\n",
    "            \"image\": image_info['file_name'],\n",
    "            \"category_id\": ann['category_id'],\n",
    "            \"bbox\": ann['bbox'],\n",
    "            \"label\": category_id_to_name[ann['category_id']],\n",
    "        })\n",
    "\n",
    "# Save filtered data to CSV\n",
    "val_filtered_csv_path = os.path.join(WORKING_DIR, 'val_filtered_coco.csv')\n",
    "val_filtered_df = pd.DataFrame(val_filtered_data)\n",
    "val_filtered_df.to_csv(val_filtered_csv_path, index=False)\n",
    "\n",
    "print(f\"Validation Filtered dataset saved to {os.path.abspath(val_filtered_csv_path)}\")\n",
    "\n",
    "\n",
    "# Load the filtered CSV\n",
    "val_data = pd.read_csv(val_filtered_csv_path)\n",
    "\n",
    "# Display record count per category_id to validate\n",
    "val_category_counts = val_data['category_id'].value_counts()\n",
    "print(\"Record count per category_id:\")\n",
    "print(val_category_counts)\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 857191,
     "sourceId": 1462296,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6332084,
     "sourceId": 10239510,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
