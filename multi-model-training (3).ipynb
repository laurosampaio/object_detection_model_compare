{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":10290678,"sourceType":"datasetVersion","datasetId":6368800}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T22:37:03.811657Z","iopub.execute_input":"2024-12-25T22:37:03.811889Z","iopub.status.idle":"2024-12-25T22:37:09.992596Z","shell.execute_reply.started":"2024-12-25T22:37:03.811867Z","shell.execute_reply":"2024-12-25T22:37:09.991573Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.54-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.3.54-py3-none-any.whl (903 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m903.1/903.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.54 ultralytics-thop-2.0.13\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport torch\nimport torchvision\nimport tensorflow as tf\nfrom torchvision.models import vit_b_32, ViT_B_32_Weights\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom ultralytics import YOLO\nfrom sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom pycocotools.coco import COCO\nimport cv2\nimport gc\nimport pickle\nimport yaml","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T22:37:09.993564Z","iopub.execute_input":"2024-12-25T22:37:09.993913Z","iopub.status.idle":"2024-12-25T22:37:24.910208Z","shell.execute_reply.started":"2024-12-25T22:37:09.993883Z","shell.execute_reply":"2024-12-25T22:37:24.909311Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Paths\nTRAIN_PATH = '/kaggle/input/coco-2017-dataset/coco2017/train2017'\nVAL_PATH = '/kaggle/input/coco-2017-dataset/coco2017/val2017'\nANNOTATIONS_PATH = '/kaggle/input/coco-2017-dataset/coco2017/annotations'\nFILTERED_DATASET = '/kaggle/input/filtered-coco-dataset'\nWORKING_DIR = '/kaggle/working'\nFILTERED_CATEGORIES = ['person', 'cat', 'dog']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T22:37:24.911068Z","iopub.execute_input":"2024-12-25T22:37:24.911611Z","iopub.status.idle":"2024-12-25T22:37:24.915305Z","shell.execute_reply.started":"2024-12-25T22:37:24.911586Z","shell.execute_reply":"2024-12-25T22:37:24.914591Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class DataProcessor:\n    def __init__(self, train_csv_path, test_csv_path):\n        self.train_data = pd.read_csv(train_csv_path)\n        self.test_data = pd.read_csv(test_csv_path)\n        self.label_encoder = LabelEncoder()\n        \n    def preprocess_image(self, image_path, target_size=(224, 224)):\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, target_size)\n        image = image / 255.0\n        return image\n\n    def load_data(self, data, path_prefix):\n        images = []\n        labels = []\n        for _, row in data.iterrows():\n            image_path = os.path.join(path_prefix, row['image'])\n            images.append(self.preprocess_image(image_path))\n            labels.append(row['category_id'])\n        \n        images = np.array(images)\n        labels = np.array(labels)\n        \n        # Encode labels\n        labels_encoded = self.label_encoder.fit_transform(labels)\n        labels_one_hot = to_categorical(labels_encoded)\n        \n        return images, labels_one_hot","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T22:37:24.917143Z","iopub.execute_input":"2024-12-25T22:37:24.917370Z","iopub.status.idle":"2024-12-25T22:37:24.935838Z","shell.execute_reply.started":"2024-12-25T22:37:24.917351Z","shell.execute_reply":"2024-12-25T22:37:24.935016Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class MetricsEvaluator:\n    def __init__(self, working_dir, timestamp):\n        self.working_dir = working_dir\n        self.timestamp = timestamp\n        \n    def evaluate_all_models(self, results_paths):\n        \"\"\"Evaluate all models using saved results\"\"\"\n        print(\"\\nEvaluating model performance...\")\n        \n        # Load test data\n        X_test = np.load(os.path.join(self.working_dir, f'X_test_{self.timestamp}.npy'))\n        y_test = np.load(os.path.join(self.working_dir, f'y_test_{self.timestamp}.npy'))\n        \n        histories = {}\n        predictions = {}\n        \n        # Load results for each model\n        for model_name, path in results_paths.items():\n            model_dir = os.path.join(self.working_dir, path)\n            \n            # Load history\n            with open(os.path.join(model_dir, 'history.pkl'), 'rb') as f:\n                histories[model_name] = pickle.load(f)\n            \n            # Load predictions\n            predictions[model_name] = np.load(os.path.join(model_dir, 'predictions.npy'))\n        \n        # Plot metrics\n        self.plot_metrics(histories, predictions, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T22:37:24.936804Z","iopub.execute_input":"2024-12-25T22:37:24.936994Z","iopub.status.idle":"2024-12-25T22:37:24.954873Z","shell.execute_reply.started":"2024-12-25T22:37:24.936977Z","shell.execute_reply":"2024-12-25T22:37:24.954035Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class ModelTrainer:\n    def __init__(self, data_processor):\n        self.data_processor = data_processor\n        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        self.working_dir = WORKING_DIR\n        \n    def train_mobilenet(self, X_train, y_train, X_test, y_test):\n        \"\"\"Train MobileNetV2 model\"\"\"\n        print(\"Training MobileNetV2...\")\n        \n        # Build the model\n        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        \n        # Unfreeze some layers for fine-tuning\n        for layer in base_model.layers[-30:]:\n            layer.trainable = True\n            \n        # Add classification head\n        inputs = Input(shape=(224, 224, 3))\n        x = base_model(inputs)\n        x = GlobalAveragePooling2D()(x)\n        x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n        x = Dropout(0.5)(x)\n        x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n        x = Dropout(0.3)(x)\n        outputs = Dense(len(self.data_processor.label_encoder.classes_), activation='softmax')(x)\n        model = Model(inputs, outputs)\n        \n        # Compile model\n        optimizer = Adam(learning_rate=0.0001)\n        model.compile(optimizer=optimizer,\n                     loss='categorical_crossentropy',\n                     metrics=['accuracy'])\n        \n        # Train model with reduced batch size and memory optimization\n        history = model.fit(\n            X_train, y_train,\n            validation_data=(X_test, y_test),\n            epochs=30,\n            batch_size=16,  # Reduced batch size to save memory\n            verbose=1\n        )\n        \n        return history.history, model\n    \n    def train_faster_rcnn(self, X_train, y_train, X_test, y_test):\n        \"\"\"Train Faster R-CNN model with memory optimization\"\"\"\n        print(\"Training Faster R-CNN...\")\n        \n        # Initialize Faster R-CNN with updated weights parameter\n        model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n            weights=torchvision.models.detection.FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n        )\n        model.train()\n        \n        # Rest of the method remains the same\n        num_classes = len(self.data_processor.label_encoder.classes_) + 1  # +1 for background\n        in_features = model.roi_heads.box_predictor.cls_score.in_features\n        model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n            in_features, num_classes)\n        \n        # Move model to GPU if available\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        model = model.to(device)\n        \n        def prepare_detection_targets(images, labels, device):\n            targets = []\n            for img_idx in range(len(images)):\n                label_idx = labels[img_idx].argmax()\n                boxes = torch.FloatTensor([[100, 100, 124, 124]]).to(device)  # Example box\n                \n                target = {\n                    'boxes': boxes,\n                    'labels': torch.tensor([label_idx + 1], dtype=torch.int64).to(device),\n                    'image_id': torch.tensor([img_idx]).to(device),\n                    'area': (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]),\n                    'iscrowd': torch.zeros((1,), dtype=torch.int64).to(device)\n                }\n                targets.append(target)\n            return targets\n        \n        # Training parameters\n        params = [p for p in model.parameters() if p.requires_grad]\n        optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n        num_epochs = 30\n        batch_size = 8  # Reduced batch size\n        \n        history = {'train_loss': [], 'val_loss': []}\n        \n        for epoch in range(num_epochs):\n            model.train()\n            epoch_loss = 0\n            num_batches = 0\n            \n            # Process in smaller batches\n            for i in range(0, len(X_train), batch_size):\n                batch_images = X_train[i:i+batch_size]\n                batch_labels = y_train[i:i+batch_size]\n                \n                # Clear memory\n                torch.cuda.empty_cache()\n                \n                # Prepare data\n                images = [torch.FloatTensor(img).permute(2, 0, 1).to(device) for img in batch_images]\n                targets = prepare_detection_targets(batch_images, batch_labels, device)\n                \n                # Forward pass\n                loss_dict = model(images, targets)\n                losses = sum(loss for loss in loss_dict.values())\n                \n                # Backward pass\n                optimizer.zero_grad()\n                losses.backward()\n                optimizer.step()\n                \n                epoch_loss += losses.item()\n                num_batches += 1\n                \n                # Free up memory\n                del images, targets, loss_dict, losses\n                torch.cuda.empty_cache()\n            \n            avg_loss = epoch_loss / num_batches\n            history['train_loss'].append(avg_loss)\n            print(f'Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}')\n        \n        return history, model\n    \n    def train_yolo(self, X_train, y_train, X_test, y_test):\n        \"\"\"Train YOLOv8 model\"\"\"\n        print(\"Training YOLOv8...\")\n        \n        # Initialize YOLOv8 with smaller image size\n        model = YOLO('yolov8n.pt')  # Using smallest YOLOv8 model\n        \n        # Prepare YOLO-specific dataset format\n        dataset_path = os.path.join(self.working_dir, 'yolo_dataset')\n        os.makedirs(dataset_path, exist_ok=True)\n        \n        # Save images and labels in YOLO format\n        train_yaml = {\n            'path': dataset_path,\n            'train': 'images/train',\n            'val': 'images/val',\n            'nc': len(self.data_processor.label_encoder.classes_),\n            'names': list(self.data_processor.label_encoder.classes_)\n        }\n        \n        with open(os.path.join(dataset_path, 'dataset.yaml'), 'w') as f:\n            yaml.dump(train_yaml, f)\n        \n        # Train with memory-optimized parameters\n        history = model.train(\n            data=os.path.join(dataset_path, 'dataset.yaml'),\n            epochs=30,\n            imgsz=224,\n            batch=8,  # Reduced batch size\n            cache=False  # Disable caching to save memory\n        )\n        \n        return vars(history), model\n    \n    def train_vit(self, X_train, y_train, X_test, y_test):\n        \"\"\"Train Vision Transformer model\"\"\"\n        print(\"Training ViT...\")\n        \n        # Initialize ViT\n        model = vit_b_32(weights=ViT_B_32_Weights.DEFAULT)\n        \n        # Modify for number of classes\n        num_classes = len(self.data_processor.label_encoder.classes_)\n        model.heads = torch.nn.Linear(model.heads.in_features, num_classes)\n        \n        # Move to GPU if available\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        model = model.to(device)\n        \n        return self._train_torch_model(model, X_train, y_train, X_test, y_test, \"vit\")\n    \n    def _train_torch_model(self, model, X_train, y_train, X_test, y_test, model_name):\n        \"\"\"Generic PyTorch training loop with memory optimization\"\"\"\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        # Training parameters\n        batch_size = 16  # Reduced batch size\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n        criterion = torch.nn.CrossEntropyLoss()\n        num_epochs = 30\n        \n        history = {\n            'train_loss': [],\n            'val_loss': [],\n            'train_acc': [],\n            'val_acc': []\n        }\n        \n        for epoch in range(num_epochs):\n            model.train()\n            train_loss = 0\n            train_correct = 0\n            num_batches = 0\n            \n            # Training loop\n            for i in range(0, len(X_train), batch_size):\n                # Clear cache periodically\n                if i % (batch_size * 10) == 0:\n                    torch.cuda.empty_cache()\n                \n                batch_x = torch.FloatTensor(X_train[i:i+batch_size]).to(device)\n                batch_y = torch.FloatTensor(y_train[i:i+batch_size]).to(device)\n                \n                optimizer.zero_grad()\n                outputs = model(batch_x)\n                loss = criterion(outputs, batch_y)\n                loss.backward()\n                optimizer.step()\n                \n                train_loss += loss.item()\n                _, predicted = torch.max(outputs.data, 1)\n                _, true_classes = torch.max(batch_y, 1)\n                train_correct += (predicted == true_classes).sum().item()\n                num_batches += 1\n                \n                # Free memory\n                del batch_x, batch_y, outputs, loss\n            \n            # Calculate metrics\n            train_loss = train_loss / num_batches\n            train_acc = train_correct / len(X_train)\n            \n            history['train_loss'].append(train_loss)\n            history['train_acc'].append(train_acc)\n            \n            print(f'Epoch {epoch+1}/{num_epochs} - loss: {train_loss:.4f} - acc: {train_acc:.4f}')\n            \n            # Clear memory after each epoch\n            torch.cuda.empty_cache()\n            gc.collect()\n        \n        return history, model\n    \n    def _save_model_results(self, model_name, history, predictions=None):\n        \"\"\"Save training history and predictions\"\"\"\n        results_dir = os.path.join(self.working_dir, f'{model_name}_{self.timestamp}')\n        os.makedirs(results_dir, exist_ok=True)\n        \n        # Save history\n        with open(os.path.join(results_dir, 'history.pkl'), 'wb') as f:\n            pickle.dump(history, f)\n            \n        # Save predictions if available\n        if predictions is not None:\n            np.save(os.path.join(results_dir, 'predictions.npy'), predictions)\n            \n    def _get_predictions(self, model, X_test):\n        \"\"\"Get predictions for evaluation\"\"\"\n        if isinstance(model, tf.keras.Model):\n            return model.predict(X_test)\n        else:\n            model.eval()\n            with torch.no_grad():\n                return model(torch.FloatTensor(X_test)).numpy()\n                \n    def train_models(self):\n        \"\"\"Train all models sequentially with memory management\"\"\"\n        print(\"Starting model training sequence...\")\n        \n        # Dictionary to store paths to saved results\n        results_paths = {}\n        \n        # Load and process data once\n        print(\"Loading and processing data...\")\n        X_train, y_train = self.data_processor.load_data(\n            self.data_processor.train_data, TRAIN_PATH)\n        X_test, y_test = self.data_processor.load_data(\n            self.data_processor.test_data, TRAIN_PATH)\n        \n        # Save test data for later evaluation\n        np.save(os.path.join(self.working_dir, f'X_test_{self.timestamp}.npy'), X_test)\n        np.save(os.path.join(self.working_dir, f'y_test_{self.timestamp}.npy'), y_test)\n        \n        try:\n            # Train MobileNetV2\n            #print(\"\\nTraining MobileNetV2...\")\n            #history, model = self.train_mobilenet(X_train, y_train, X_test, y_test)\n            #predictions = self._get_predictions(model, X_test)\n            #self._save_model_results('mobilenet', history, predictions)\n            #results_paths['mobilenet'] = f'mobilenet_{self.timestamp}'\n            \n            # Clear memory\n            #del model, history, predictions\n            #tf.keras.backend.clear_session()\n            #gc.collect()\n            \n            # Train Faster R-CNN\n            print(\"\\nTraining Faster R-CNN...\")\n            history, model = self.train_faster_rcnn(X_train, y_train, X_test, y_test)\n            predictions = self._get_predictions(model, X_test)\n            self._save_model_results('faster_rcnn', history, predictions)\n            results_paths['faster_rcnn'] = f'faster_rcnn_{self.timestamp}'\n            \n            # Clear memory\n            del model, history, predictions\n            torch.cuda.empty_cache()\n            gc.collect()\n            \n            # Train YOLOv8\n            print(\"\\nTraining YOLOv8...\")\n            history, model = self.train_yolo(X_train, y_train, X_test, y_test)\n            predictions = self._get_predictions(model, X_test)\n            self._save_model_results('yolo', history, predictions)\n            results_paths['yolo'] = f'yolo_{self.timestamp}'\n            \n            # Clear memory\n            del model, history, predictions\n            gc.collect()\n            \n            # Train ViT\n            print(\"\\nTraining ViT...\")\n            history, model = self.train_vit(X_train, y_train, X_test, y_test)\n            predictions = self._get_predictions(model, X_test)\n            self._save_model_results('vit', history, predictions)\n            results_paths['vit'] = f'vit_{self.timestamp}'\n            \n            # Clear memory\n            del model, history, predictions\n            torch.cuda.empty_cache()\n            gc.collect()\n            \n        except Exception as e:\n            print(f\"Error during training: {str(e)}\")\n            raise e\n        \n        finally:\n            # Clean up training data\n            del X_train, y_train\n            gc.collect()\n            \n        return results_paths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T22:37:24.955595Z","iopub.execute_input":"2024-12-25T22:37:24.955777Z","iopub.status.idle":"2024-12-25T22:37:24.984558Z","shell.execute_reply.started":"2024-12-25T22:37:24.955761Z","shell.execute_reply":"2024-12-25T22:37:24.983774Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def main():\n    # Initialize data processor\n    data_processor = DataProcessor(\n        os.path.join(FILTERED_DATASET, 'train_data.csv'),\n        os.path.join(FILTERED_DATASET, 'test_data.csv')\n    )\n    \n    # Initialize trainer\n    trainer = ModelTrainer(data_processor)\n    \n    # Train all models and get paths to results\n    results_paths = trainer.train_models()\n    \n    # Evaluate results\n    evaluator = MetricsEvaluator(WORKING_DIR, trainer.timestamp)\n    evaluator.evaluate_all_models(results_paths)\n    \n    print(\"Training and evaluation complete. Results saved in working directory.\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T22:37:24.985283Z","iopub.execute_input":"2024-12-25T22:37:24.985469Z"}},"outputs":[{"name":"stdout","text":"Starting model training sequence...\nLoading and processing data...\n\nTraining Faster R-CNN...\nTraining Faster R-CNN...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n100%|██████████| 160M/160M [00:00<00:00, 202MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Loss: 0.1574\nEpoch 2/30 - Loss: 0.1426\nEpoch 3/30 - Loss: 0.1412\nEpoch 4/30 - Loss: 0.1362\nEpoch 5/30 - Loss: 0.1320\nEpoch 6/30 - Loss: 0.1272\nEpoch 7/30 - Loss: 0.1190\nEpoch 8/30 - Loss: 0.1199\nEpoch 9/30 - Loss: 0.1089\nEpoch 10/30 - Loss: 0.0862\nEpoch 11/30 - Loss: 0.0689\nEpoch 12/30 - Loss: 0.0551\nEpoch 13/30 - Loss: 0.0444\nEpoch 14/30 - Loss: 0.0366\nEpoch 15/30 - Loss: 0.0300\nEpoch 16/30 - Loss: 0.0252\nEpoch 17/30 - Loss: 0.0304\nEpoch 18/30 - Loss: 0.0240\nEpoch 19/30 - Loss: 0.0209\nEpoch 20/30 - Loss: 0.0219\nEpoch 21/30 - Loss: 0.0240\nEpoch 22/30 - Loss: 0.0206\nEpoch 23/30 - Loss: 0.0200\n","output_type":"stream"}],"execution_count":null}]}